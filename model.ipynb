{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fe992e",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Our model begins with a Regression Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7dfadb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Regression Classifier.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Statsmodels.\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc7bfc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/nathanlonghurst/.cache/kagglehub/datasets/lashagoch/life-expectancy-who-updated/versions/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m model = RandomForestClassifier()\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Train the model.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Make predictions.\u001b[39;00m\n\u001b[32m     30\u001b[39m y_pred = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ACME/vol3-project/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ACME/vol3-project/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:418\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    411\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    412\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSum of y is not strictly positive which \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis necessary for Poisson regression.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    414\u001b[39m         )\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._n_samples, \u001b[38;5;28mself\u001b[39m.n_outputs_ = y.shape\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m y, expanded_class_weight = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) != DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y.flags.contiguous:\n\u001b[32m    421\u001b[39m     y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ACME/vol3-project/.venv/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:830\u001b[39m, in \u001b[36mForestClassifier._validate_y_class_weight\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    829\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    832\u001b[39m     y = np.copy(y)\n\u001b[32m    833\u001b[39m     expanded_class_weight = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ACME/vol3-project/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:221\u001b[39m, in \u001b[36mcheck_classification_targets\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m    213\u001b[39m y_type = type_of_target(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmultilabel-sequences\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m ]:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Maybe you are trying to fit a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    223\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclassifier, which expects discrete classes on a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mregression target with continuous values.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "# Load dataset.\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lashagoch/life-expectancy-who-updated\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file = \"Life-Expectancy-Data-Updated.csv\"\n",
    "\n",
    "# TODO:  Correct features and assign target.\n",
    "data = pd.read_csv(path + \"/\" + file)\n",
    "data.columns\n",
    "X = data[['Infant_deaths', 'Under_five_deaths',\n",
    "       'Adult_mortality', 'Alcohol_consumption', 'Hepatitis_B', 'Measles',\n",
    "       'BMI', 'Polio', 'Diphtheria', 'Incidents_HIV', 'GDP_per_capita',\n",
    "       'Population_mln', 'Thinness_ten_nineteen_years',\n",
    "       'Thinness_five_nine_years', 'Schooling', 'Economy_status_Developed',\n",
    "       'Economy_status_Developing']]\n",
    "\n",
    "y = data['Life_expectancy']\n",
    "\n",
    "# Split data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier instance.\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Train the model.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy:  {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee50d640",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "\n",
    "Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff377d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load dataset.\n",
    "# # TODO:  Correct features and assign target.\n",
    "# data = pd.DataFrame(data)\n",
    "# X = data[['feature1', 'feature2']]\n",
    "# y = data['target']\n",
    "\n",
    "# # Add a constant (intercept) to the features.\n",
    "# X = sm.add_constant(X)\n",
    "\n",
    "# # Create and fit a Logistic Regression model.\n",
    "# model = sm.Logit(y, X)\n",
    "# results = model.fit()\n",
    "\n",
    "# # Print the summary of results.\n",
    "# print(results.summary())\n",
    "\n",
    "# # Make predictions (requires a threshold for classification).\n",
    "# predictions = results.predict(X)\n",
    "# binary_predictions = (predictions > 0.5).astype(int)\n",
    "# print(binary_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vol3-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
