{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fe992e",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Our model begins with a Regression Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db884ed3",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "We attempt three models:\n",
    "\n",
    "1. RandomForestRegressor  \n",
    "2. LinearRegression  \n",
    "3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfadb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathanlonghurst/Desktop/ACME/vol3-project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Regression Classifier.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Statsmodels.\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39159389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/nathanlonghurst/.cache/kagglehub/datasets/lashagoch/life-expectancy-who-updated/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Load dataset.\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lashagoch/life-expectancy-who-updated\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file = \"Life-Expectancy-Data-Updated.csv\"\n",
    "\n",
    "data = pd.read_csv(path + \"/\" + file)\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "# take log of GDP per capita\n",
    "data[\"GDP_per_capita\"] = np.log10(data[\"GDP_per_capita\"])\n",
    "\n",
    "# take average vaccination percentage\n",
    "data[\"Vaccination_score\"] = (data[\"Hepatitis_B\"] + data[\"Polio\"] + data[\"Diphtheria\"])/3\n",
    "\n",
    "# Compute Lifestyle Index\n",
    "BMI_score = 1*(data[\"BMI\"] <= 30)*(data[\"BMI\"] > 25) + 2*(data[\"BMI\"] > 30)\n",
    "Alcohol_score = 1*(data[\"Alcohol_consumption\"] <= 9.722)*(data[\"Alcohol_consumption\"] > 3.241) + 2*(data[\"Alcohol_consumption\"] > 9.722)\n",
    "data[\"Lifestyle_index\"] = BMI_score + Alcohol_score\n",
    "\n",
    "X = data[['Alcohol_consumption', 'Hepatitis_B', 'Measles',\n",
    "       'BMI', 'Polio', 'Diphtheria', 'Incidents_HIV', 'GDP_per_capita',\n",
    "       'Population_mln', 'Thinness_ten_nineteen_years',\n",
    "       'Thinness_five_nine_years', 'Schooling', 'Economy_status_Developed', 'Vaccination_score', 'Lifestyle_index']]\n",
    "\n",
    "y = data['Life_expectancy']\n",
    "\n",
    "# Split data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555137b7",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "\n",
    "RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bfc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/lashagoch/life-expectancy-who-updated?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104k/104k [00:00<00:00, 1.45MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\valeh\\.cache\\kagglehub\\datasets\\lashagoch\\life-expectancy-who-updated\\versions\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996240193583538\n"
     ]
    }
   ],
   "source": [
    "# Load dataset.\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lashagoch/life-expectancy-who-updated\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file = \"Life-Expectancy-Data-Updated.csv\"\n",
    "\n",
    "# TODO:  Correct features and assign target.\n",
    "data = pd.read_csv(path + \"/\" + file)\n",
    "data.columns\n",
    "X = data[['Infant_deaths', 'Under_five_deaths',\n",
    "       'Adult_mortality', 'Alcohol_consumption', 'Hepatitis_B', 'Measles',\n",
    "       'BMI', 'Polio', 'Diphtheria', 'Incidents_HIV', 'GDP_per_capita',\n",
    "       'Population_mln', 'Thinness_ten_nineteen_years',\n",
    "       'Thinness_five_nine_years', 'Schooling', 'Economy_status_Developed',\n",
    "       'Economy_status_Developing']]\n",
    "\n",
    "y = data['Life_expectancy']\n",
    "\n",
    "# Split data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier instance.\n",
    "model = RandomForestRegressor(oob_score=True)\n",
    "\n",
    "# Train the model.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model.\n",
    "print(model.oob_score_)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'Accuracy:  {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee50d640",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "\n",
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060935be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff377d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  [0.6]\n",
      "Intercept:  2.2\n",
      "Predictions:  [5.8 6.4]\n"
     ]
    }
   ],
   "source": [
    "# Prepare data.\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)    # Single feature.\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Create a Linear Regression model object.\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to data.\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions.\n",
    "new_X = np.array([6, 7]).reshape(-1, 1)\n",
    "predictions = model.predict(new_X)\n",
    "\n",
    "# Access model attributes.\n",
    "slope = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Print results.\n",
    "print(f'Coefficient:  {slope}')\n",
    "print(f'Intercept:  {intercept}')\n",
    "print(f'Predictions:  {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b68c0f",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct XGBoost regression model.\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100,       # Number of boosted trees.\n",
    "    learning_rate=0.1,      # Shrinkage (eta).\n",
    "    max_depth=6,            # Tree depth.\n",
    "    subsample=1.0,          # Row sampling.\n",
    "    colsample_bytree=1.0,   # Feature sampling.\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Fit model and predict results.\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995be5d",
   "metadata": {},
   "source": [
    "## Model 4 (Optional)\n",
    "\n",
    "StatsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95770115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load dataset.\n",
    "# # TODO:  Correct features and assign target.\n",
    "# data = pd.DataFrame(data)\n",
    "# X = data[['feature1', 'feature2']]\n",
    "# y = data['target']\n",
    "\n",
    "# # Add a constant (intercept) to the features.\n",
    "# X = sm.add_constant(X)\n",
    "\n",
    "# # Create and fit a Logistic Regression model.\n",
    "# model = sm.Logit(y, X)\n",
    "# results = model.fit()\n",
    "\n",
    "# # Print the summary of results.\n",
    "# print(results.summary())\n",
    "\n",
    "# # Make predictions (requires a threshold for classification).\n",
    "# predictions = results.predict(X)\n",
    "# binary_predictions = (predictions > 0.5).astype(int)\n",
    "# print(binary_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vol3-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
